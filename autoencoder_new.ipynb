{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'sensordata.ACC', 'sensordata.GYR', 'sensordata.GRV',\n",
      "       'sensordata.MAG', 'sensordata.ROT', 'duration'],\n",
      "      dtype='object', name='stype')\n",
      "Dataset shapes: \n",
      "(332, 800, 17)\n",
      "(332,)\n",
      "(332,)\n",
      "(2656, 100, 17) (2656,)\n",
      "train-test shapes: \n",
      "(232, 100, 17) (100, 100, 17) (232,) (100,)\n",
      "(232, 100, 17) (100, 100, 17) (232,) (100,)\n",
      "(2324, 100, 17) (2324,)\n"
     ]
    }
   ],
   "source": [
    "file_path = './combined_all_interpol_synced_4sec_800samples_prot4.pkl'\n",
    "\n",
    "dataFrame = pd.read_pickle(file_path)\n",
    "\n",
    "\n",
    "print(dataFrame.columns)\n",
    "y = np.array(dataFrame['uid'])\n",
    "x = None\n",
    "for col in dataFrame.columns:\n",
    "    if 'sensordata' in col:\n",
    "        if x is None:\n",
    "            x = np.array(dataFrame[col].apply(lambda x: np.array(x)).to_list())\n",
    "            #print(x_data.shape)\n",
    "        else:\n",
    "            x_data = np.array(dataFrame[col].apply(lambda x: np.array(x)).to_list())\n",
    "            #print(x_data.shape)\n",
    "            x = np.append(x, x_data , axis=2)\n",
    "dur = np.array(dataFrame['duration'])\n",
    "print(\"Dataset shapes: \")\n",
    "print(x.shape)\n",
    "print(dur.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "def split_features_and_adjust_labels(x, y, window_size=100, overlap=0.4):\n",
    "    num_samples = x.shape[0]\n",
    "    num_timesteps = x.shape[1]\n",
    "    num_features = x.shape[2]\n",
    "\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    num_segments = int((num_timesteps - window_size) / step_size) + 1\n",
    "\n",
    "    split_x = np.zeros((num_samples * num_segments, window_size, num_features))\n",
    "    adjusted_y = np.repeat(y, num_segments)\n",
    "\n",
    "    segment_index = 0\n",
    "    for sample_index in range(num_samples):\n",
    "        for i in range(0, num_timesteps - window_size + 1, step_size):\n",
    "          split_x[segment_index] = x[sample_index, i : i + window_size, :]\n",
    "          segment_index += 1\n",
    "\n",
    "    return split_x, adjusted_y, num_segments\n",
    "\n",
    "def get_aligned_and_rest(split_x, adjusted_y,num_segments):\n",
    "    x_aligned = []\n",
    "    y_aligned = []\n",
    "    x_other = []\n",
    "    y_other = []\n",
    "\n",
    "    for i in range(len(adjusted_y)):\n",
    "        if i % num_segments == 0:\n",
    "            x_aligned.append(split_x[i])\n",
    "            y_aligned.append(adjusted_y[i])\n",
    "        else:\n",
    "            x_other.append(split_x[i])\n",
    "            y_other.append(adjusted_y[i])\n",
    "    return np.array(x_aligned), np.array(y_aligned), np.array(x_other), np.array(y_other)\n",
    "\n",
    "\n",
    "split_x, adjusted_y,num_segments  = split_features_and_adjust_labels(x,y,window_size=100,overlap=0)\n",
    "print(split_x.shape, adjusted_y.shape)\n",
    "x_aligned, y_aligned, x_other, y_other = get_aligned_and_rest(split_x,adjusted_y, num_segments)\n",
    "\n",
    "\n",
    "y_aligned = y_aligned.astype(str)\n",
    "y_other = y_other.astype(str)\n",
    "x = x_aligned\n",
    "y = y_aligned\n",
    "\n",
    "\n",
    "class_label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = class_label_encoder.fit_transform(y)\n",
    "y_other = class_label_encoder.transform(y_other)\n",
    "n_classes = class_label_encoder.classes_.shape[0]\n",
    "\n",
    "print(\"train-test shapes: \")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "x_other_scaled = scaler.transform(x_other.reshape(-1, x_other.shape[-1])).reshape(x_other.shape)\n",
    "\n",
    "\n",
    "print(x_other_scaled.shape, y_other.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_12 (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_13 (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import losses,Model\n",
    "from keras.models import load_model\n",
    "latent_dim = 64\n",
    "MLength = 100\n",
    "dims = 17\n",
    "\n",
    "\n",
    "MPATH = './new_autoencoder_model_target_0'\n",
    "input_shape = all_x_train.shape[1:]\n",
    "\n",
    "class SaveModelCheckpoint(keras.callbacks.Callback):\n",
    "    def __init__(self, filepath, interval=10):\n",
    "        super(SaveModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.interval = interval\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        filepath = self.filepath\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        print(f\"Saving history to {filepath}\")\n",
    "        with open(self.filepath+'.json', 'a') as f:\n",
    "            json.dump(self.model.history.history, f, indent=4)\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "save_checkpoint_callback = SaveModelCheckpoint(MPATH, interval=10)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True), save_checkpoint_callback]\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim, mLength, dims, **kwargs):\n",
    "      super(Autoencoder, self).__init__(**kwargs)\n",
    "      self.latent_dim = latent_dim\n",
    "      self.mLength = mLength\n",
    "      self.dims = dims\n",
    "      self.encoder = tf.keras.Sequential([\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(self.latent_dim, activation='relu'),\n",
    "      ])\n",
    "      self.decoder = tf.keras.Sequential([\n",
    "          layers.Dense(self.mLength * self.dims, activation='linear'),\n",
    "          layers.Reshape((self.mLength, self.dims)),\n",
    "      ])\n",
    "\n",
    "  def call(self, x):\n",
    "      encoded = self.encoder(x)\n",
    "      decoded = self.decoder(encoded)\n",
    "      return decoded\n",
    "\n",
    "  def get_config(self):\n",
    "      # Include all parameters needed for re-creation\n",
    "      config = super(Autoencoder, self).get_config()\n",
    "      config.update({\n",
    "          \"latent_dim\": self.latent_dim,\n",
    "          \"mLength\": self.mLength,\n",
    "          \"dims\": self.dims,\n",
    "      })\n",
    "      return config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "      # Return an instance of the model\n",
    "      return cls(**config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim,MLength,dims)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                    loss=losses.MeanSquaredError())\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPATH = './new_autoencoder_model'\n",
    "input_shape = x_train.shape[1:]\n",
    "class SaveModelCheckpoint(keras.callbacks.Callback):\n",
    "    def __init__(self, filepath, interval=10):\n",
    "        super(SaveModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.interval = interval\n",
    "    def on_train_end(self, logs=None):\n",
    "        filepath = self.filepath.format(epoch=\"0\")\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        print(f\"Saving history to {filepath}\")\n",
    "        with open(self.filepath+'.json', 'a') as f:\n",
    "            json.dump(self.model.history.history, f, indent=4)\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "save_checkpoint_callback = SaveModelCheckpoint(MPATH +'_{epoch}', interval=10)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True), save_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2979 - val_loss: 0.7554\n",
      "Epoch 2/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 1.3137 - val_loss: 0.7364\n",
      "Epoch 3/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1714 - val_loss: 0.7112\n",
      "Epoch 4/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 1.0236 - val_loss: 0.6734\n",
      "Epoch 5/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0300 - val_loss: 0.6237\n",
      "Epoch 6/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7814 - val_loss: 0.5626\n",
      "Epoch 7/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7157 - val_loss: 0.5072\n",
      "Epoch 8/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8747 - val_loss: 0.4533\n",
      "Epoch 9/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5672 - val_loss: 0.4178\n",
      "Epoch 10/100\n",
      "\u001b[1m 1/47\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3950Saving model to ./new_autoencoder_model_10\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5945 - val_loss: 0.3845\n",
      "Epoch 11/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4464 - val_loss: 0.3614\n",
      "Epoch 12/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.4462 - val_loss: 0.3368\n",
      "Epoch 13/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4835 - val_loss: 0.3206\n",
      "Epoch 14/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.4606 - val_loss: 0.3075\n",
      "Epoch 15/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5057 - val_loss: 0.2971\n",
      "Epoch 16/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3919 - val_loss: 0.2894\n",
      "Epoch 17/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.4045 - val_loss: 0.2783\n",
      "Epoch 18/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4185 - val_loss: 0.2711\n",
      "Epoch 19/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.4127 - val_loss: 0.2648\n",
      "Epoch 20/100\n",
      "\u001b[1m 3/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.4614Saving model to ./new_autoencoder_model_20\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3762 - val_loss: 0.2587\n",
      "Epoch 21/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3391 - val_loss: 0.2540\n",
      "Epoch 22/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3606 - val_loss: 0.2483\n",
      "Epoch 23/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3909 - val_loss: 0.2452\n",
      "Epoch 24/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3730 - val_loss: 0.2401\n",
      "Epoch 25/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3059 - val_loss: 0.2355\n",
      "Epoch 26/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3089 - val_loss: 0.2321\n",
      "Epoch 27/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3046 - val_loss: 0.2289\n",
      "Epoch 28/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3140 - val_loss: 0.2251\n",
      "Epoch 29/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3131 - val_loss: 0.2225\n",
      "Epoch 30/100\n",
      "\u001b[1m 3/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.5165Saving model to ./new_autoencoder_model_30\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3203 - val_loss: 0.2193\n",
      "Epoch 31/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2858 - val_loss: 0.2164\n",
      "Epoch 32/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2632 - val_loss: 0.2137\n",
      "Epoch 33/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2748 - val_loss: 0.2116\n",
      "Epoch 34/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2803 - val_loss: 0.2091\n",
      "Epoch 35/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2796 - val_loss: 0.2068\n",
      "Epoch 36/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.2969 - val_loss: 0.2048\n",
      "Epoch 37/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.2477 - val_loss: 0.2026\n",
      "Epoch 38/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2414 - val_loss: 0.2008\n",
      "Epoch 39/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2452 - val_loss: 0.2028\n",
      "Epoch 40/100\n",
      "\u001b[1m 3/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2493 Saving model to ./new_autoencoder_model_40\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2553 - val_loss: 0.1997\n",
      "Epoch 41/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2205 - val_loss: 0.1975\n",
      "Epoch 42/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2599 - val_loss: 0.1959\n",
      "Epoch 43/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.2637 - val_loss: 0.1934\n",
      "Epoch 44/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.2471 - val_loss: 0.1920\n",
      "Epoch 45/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2422 - val_loss: 0.1911\n",
      "Epoch 46/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2024 - val_loss: 0.1902\n",
      "Epoch 47/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2153 - val_loss: 0.1882\n",
      "Epoch 48/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.2171 - val_loss: 0.1864\n",
      "Epoch 49/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2143 - val_loss: 0.1855\n",
      "Epoch 50/100\n",
      "\u001b[1m 2/47\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.1783Saving model to ./new_autoencoder_model_50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2065 - val_loss: 0.1836\n",
      "Epoch 51/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2261 - val_loss: 0.1822\n",
      "Epoch 52/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1998 - val_loss: 0.1823\n",
      "Epoch 53/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2094 - val_loss: 0.1803\n",
      "Epoch 54/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2173 - val_loss: 0.1792\n",
      "Epoch 55/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2011 - val_loss: 0.1786\n",
      "Epoch 56/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.2137 - val_loss: 0.1774\n",
      "Epoch 57/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.2004 - val_loss: 0.1769\n",
      "Epoch 58/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1873 - val_loss: 0.1756\n",
      "Epoch 59/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1982 - val_loss: 0.1750\n",
      "Epoch 60/100\n",
      "\u001b[1m 3/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1586Saving model to ./new_autoencoder_model_60\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1949 - val_loss: 0.1737\n",
      "Epoch 61/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1860 - val_loss: 0.1731\n",
      "Epoch 62/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2048 - val_loss: 0.1723\n",
      "Epoch 63/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.1866 - val_loss: 0.1711\n",
      "Epoch 64/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.1814 - val_loss: 0.1781\n",
      "Epoch 65/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.1930 - val_loss: 0.1690\n",
      "Epoch 66/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1692 - val_loss: 0.1677\n",
      "Epoch 67/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1726 - val_loss: 0.1672\n",
      "Epoch 68/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1588 - val_loss: 0.1664\n",
      "Epoch 69/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1773 - val_loss: 0.1655\n",
      "Epoch 70/100\n",
      "\u001b[1m 4/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.2524Saving model to ./new_autoencoder_model_70\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1757 - val_loss: 0.1643\n",
      "Epoch 71/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.1568 - val_loss: 0.1649\n",
      "Epoch 72/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1555 - val_loss: 0.1630\n",
      "Epoch 73/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1538 - val_loss: 0.1631\n",
      "Epoch 74/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1626 - val_loss: 0.1633\n",
      "Epoch 75/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1556 - val_loss: 0.1643\n",
      "Epoch 76/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1652 - val_loss: 0.1686\n",
      "Epoch 77/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1800 - val_loss: 0.1600\n",
      "Epoch 78/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1728 - val_loss: 0.1599\n",
      "Epoch 79/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1532 - val_loss: 0.1594\n",
      "Epoch 80/100\n",
      "\u001b[1m 2/47\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0995 : 0.1094 Saving model to ./new_autoencoder_model_80\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1398 - val_loss: 0.1572\n",
      "Epoch 81/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1616 - val_loss: 0.1571\n",
      "Epoch 82/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1478 - val_loss: 0.1563\n",
      "Epoch 83/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1552 - val_loss: 0.1556\n",
      "Epoch 84/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1422 - val_loss: 0.1546\n",
      "Epoch 85/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1366 - val_loss: 0.1547\n",
      "Epoch 86/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1537 - val_loss: 0.1533\n",
      "Epoch 87/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1273 - val_loss: 0.1537\n",
      "Epoch 88/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1460 - val_loss: 0.1533\n",
      "Epoch 89/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1430 - val_loss: 0.1522\n",
      "Epoch 90/100\n",
      "\u001b[1m 2/47\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2080  Saving model to ./new_autoencoder_model_90\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1553 - val_loss: 0.1512\n",
      "Epoch 91/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1358 - val_loss: 0.1506\n",
      "Epoch 92/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1386 - val_loss: 0.1507\n",
      "Epoch 93/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1216 - val_loss: 0.1494\n",
      "Epoch 94/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1455 - val_loss: 0.1493\n",
      "Epoch 95/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1285 - val_loss: 0.1494\n",
      "Epoch 96/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.1218 - val_loss: 0.1479\n",
      "Epoch 97/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1264 - val_loss: 0.1483\n",
      "Epoch 98/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1316 - val_loss: 0.1463\n",
      "Epoch 99/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1218 - val_loss: 0.1464\n",
      "Epoch 100/100\n",
      "\u001b[1m 3/47\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0731   Saving model to ./new_autoencoder_model_100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1209 - val_loss: 0.1453\n",
      "Saving history to ./new_autoencoder_model_0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=4,\n",
    "    callbacks=callbacks,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
